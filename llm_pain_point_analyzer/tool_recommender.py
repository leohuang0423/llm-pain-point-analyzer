#!/usr/bin/env python3
"""
LLMç—›ç‚¹åˆ†æå™¨ - å·¥å…·æ¨èæ¨¡å—
è§£å†³å·¥å…·é€‰æ‹©å†³ç­–å›°éš¾é—®é¢˜
"""

import json
import sys
import argparse
import os
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

class ToolRecommender:
    """æ™ºèƒ½å·¥å…·æ¨èå™¨"""
    
    def __init__(self, config_dir: str = None):
        """åˆå§‹åŒ–å·¥å…·æ¨èå™¨"""
        if config_dir is None:
            config_dir = os.path.join(os.path.dirname(__file__), "../config")
        
        self.config_dir = Path(config_dir)
        self.tools_db = self.load_tools_db()
        self.history_db = self.load_history_db()
        self.task_patterns = self.load_task_patterns()
        
    def load_tools_db(self) -> Dict:
        """åŠ è½½å·¥å…·æ•°æ®åº“"""
        tools_file = self.config_dir / "tools.json"
        if tools_file.exists():
            with open(tools_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # é»˜è®¤å·¥å…·æ•°æ®åº“
        return {
            "feishu_doc": {
                "description": "é£ä¹¦æ–‡æ¡£æ“ä½œï¼ˆåˆ›å»ºã€è¯»å–ã€æ›´æ–°ã€åˆ é™¤ï¼‰",
                "capabilities": ["document_creation", "content_writing", "document_management"],
                "success_rate": 0.85,
                "avg_response_time": 2.3,
                "complexity": "medium",
                "permissions_required": ["docx:document:write_only", "docx:document:read_only"],
                "input_requirements": ["title", "content", "folder_token"],
                "output_type": "document_url"
            },
            "feishu_drive": {
                "description": "é£ä¹¦äº‘ç›˜æ“ä½œï¼ˆæ–‡ä»¶ç®¡ç†ã€æ–‡ä»¶å¤¹æ“ä½œï¼‰",
                "capabilities": ["file_management", "folder_operations", "storage_access"],
                "success_rate": 0.92,
                "avg_response_time": 1.8,
                "complexity": "low",
                "permissions_required": ["drive:drive:read_only", "drive:drive:write_only"],
                "input_requirements": ["folder_token", "file_token", "action"],
                "output_type": "file_list"
            },
            "feishu_wiki": {
                "description": "é£ä¹¦çŸ¥è¯†åº“æ“ä½œï¼ˆç©ºé—´ç®¡ç†ã€èŠ‚ç‚¹æ“ä½œï¼‰",
                "capabilities": ["knowledge_management", "wiki_operations", "content_organization"],
                "success_rate": 0.78,
                "avg_response_time": 2.8,
                "complexity": "medium",
                "permissions_required": ["wiki:wiki:read_only", "wiki:wiki:write_only"],
                "input_requirements": ["space_id", "node_token", "title"],
                "output_type": "wiki_url"
            },
            "web_search": {
                "description": "ç½‘é¡µæœç´¢ï¼ˆå®æ—¶ä¿¡æ¯æŸ¥è¯¢ã€ç ”ç©¶ï¼‰",
                "capabilities": ["information_retrieval", "research", "real_time_data"],
                "success_rate": 0.65,
                "avg_response_time": 3.5,
                "complexity": "low",
                "permissions_required": ["search:api:access"],
                "input_requirements": ["query", "count", "freshness"],
                "output_type": "search_results",
                "requires_api_key": True
            },
            "web_fetch": {
                "description": "ç½‘é¡µå†…å®¹æå–ï¼ˆHTMLè½¬Markdown/Textï¼‰",
                "capabilities": ["content_extraction", "web_scraping", "text_processing"],
                "success_rate": 0.88,
                "avg_response_time": 2.1,
                "complexity": "low",
                "permissions_required": ["web:access:read_only"],
                "input_requirements": ["url", "extract_mode", "max_chars"],
                "output_type": "extracted_content"
            },
            "read": {
                "description": "æ–‡ä»¶è¯»å–ï¼ˆæ–‡æœ¬æ–‡ä»¶ã€å›¾ç‰‡ï¼‰",
                "capabilities": ["file_reading", "content_access", "data_loading"],
                "success_rate": 0.95,
                "avg_response_time": 0.5,
                "complexity": "low",
                "permissions_required": ["file:read:local"],
                "input_requirements": ["path", "offset", "limit"],
                "output_type": "file_content"
            },
            "write": {
                "description": "æ–‡ä»¶å†™å…¥ï¼ˆåˆ›å»ºã€è¦†ç›–æ–‡ä»¶ï¼‰",
                "capabilities": ["file_writing", "content_creation", "data_storage"],
                "success_rate": 0.93,
                "avg_response_time": 0.7,
                "complexity": "low",
                "permissions_required": ["file:write:local"],
                "input_requirements": ["path", "content"],
                "output_type": "file_status"
            },
            "edit": {
                "description": "æ–‡ä»¶ç¼–è¾‘ï¼ˆç²¾ç¡®æ–‡æœ¬æ›¿æ¢ï¼‰",
                "capabilities": ["file_editing", "text_manipulation", "content_modification"],
                "success_rate": 0.90,
                "avg_response_time": 0.9,
                "complexity": "medium",
                "permissions_required": ["file:write:local"],
                "input_requirements": ["path", "old_text", "new_text"],
                "output_type": "edit_status"
            },
            "exec": {
                "description": "å‘½ä»¤æ‰§è¡Œï¼ˆShellå‘½ä»¤ã€è„šæœ¬è¿è¡Œï¼‰",
                "capabilities": ["command_execution", "system_operations", "automation"],
                "success_rate": 0.82,
                "avg_response_time": 5.0,
                "complexity": "high",
                "permissions_required": ["system:exec:limited"],
                "input_requirements": ["command", "workdir", "env"],
                "output_type": "command_output",
                "risk_level": "medium"
            }
        }
    
    def load_history_db(self) -> Dict:
        """åŠ è½½å†å²ä½¿ç”¨æ•°æ®åº“"""
        history_file = self.config_dir / "history.json"
        if history_file.exists():
            with open(history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # é»˜è®¤å†å²æ•°æ®åº“
        return {
            "usage_stats": {},
            "success_rates": {},
            "recent_tasks": [],
            "user_preferences": {}
        }
    
    def load_task_patterns(self) -> Dict:
        """åŠ è½½ä»»åŠ¡æ¨¡å¼æ•°æ®åº“"""
        patterns_file = self.config_dir / "patterns.json"
        if patterns_file.exists():
            with open(patterns_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # é»˜è®¤ä»»åŠ¡æ¨¡å¼
        return {
            "document_operations": {
                "keywords": ["æ–‡æ¡£", "doc", "write", "åˆ›å»ºæ–‡æ¡£", "ç¼–è¾‘æ–‡æ¡£", "è¯»å–æ–‡æ¡£"],
                "tools": ["feishu_doc", "feishu_wiki", "write", "edit"],
                "priority": ["feishu_doc", "write", "edit", "feishu_wiki"]
            },
            "file_operations": {
                "keywords": ["æ–‡ä»¶", "file", "è¯»å–æ–‡ä»¶", "å†™å…¥æ–‡ä»¶", "ç¼–è¾‘æ–‡ä»¶", "æ–‡ä»¶å¤¹"],
                "tools": ["read", "write", "edit", "feishu_drive"],
                "priority": ["read", "write", "edit", "feishu_drive"]
            },
            "search_operations": {
                "keywords": ["æœç´¢", "search", "æŸ¥æ‰¾", "æŸ¥è¯¢", "ç ”ç©¶", "ä¿¡æ¯"],
                "tools": ["web_search", "web_fetch"],
                "priority": ["web_search", "web_fetch"]
            },
            "system_operations": {
                "keywords": ["å‘½ä»¤", "æ‰§è¡Œ", "è¿è¡Œ", "shell", "ç»ˆç«¯", "è„šæœ¬"],
                "tools": ["exec"],
                "priority": ["exec"]
            },
            "data_processing": {
                "keywords": ["å¤„ç†", "åˆ†æ", "æå–", "è½¬æ¢", "æ ¼å¼åŒ–", "æ•´ç†"],
                "tools": ["web_fetch", "read", "write"],
                "priority": ["web_fetch", "read", "write"]
            }
        }
    
    def analyze_task(self, task_description: str, context: Dict = None) -> Dict:
        """
        åˆ†æä»»åŠ¡éœ€æ±‚
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç”¨æˆ·åå¥½ã€å†å²è®°å½•ç­‰ï¼‰
            
        Returns:
            ä»»åŠ¡åˆ†æç»“æœ
        """
        task_lower = task_description.lower()
        
        # è¯†åˆ«ä»»åŠ¡ç±»å‹
        task_types = []
        for task_type, pattern in self.task_patterns.items():
            for keyword in pattern["keywords"]:
                if keyword.lower() in task_lower:
                    task_types.append(task_type)
                    break
        
        # è¯†åˆ«å¤æ‚åº¦
        complexity = self.estimate_complexity(task_description)
        
        # è¯†åˆ«è¾“å…¥éœ€æ±‚
        input_requirements = self.identify_input_requirements(task_description)
        
        # è¯†åˆ«è¾“å‡ºæœŸæœ›
        output_expectation = self.identify_output_expectation(task_description)
        
        return {
            "task_description": task_description,
            "task_types": list(set(task_types)),
            "complexity": complexity,
            "input_requirements": input_requirements,
            "output_expectation": output_expectation,
            "keywords": self.extract_keywords(task_description)
        }
    
    def estimate_complexity(self, task_description: str) -> str:
        """ä¼°è®¡ä»»åŠ¡å¤æ‚åº¦"""
        task_lower = task_description.lower()
        
        # å¤æ‚ä»»åŠ¡å…³é”®è¯
        complex_keywords = ["å¤æ‚", "å›°éš¾", "æŒ‘æˆ˜", "å¤šæ­¥éª¤", "ç³»ç»Ÿ", "é›†æˆ", "è‡ªåŠ¨åŒ–"]
        simple_keywords = ["ç®€å•", "å¿«é€Ÿ", "ç›´æ¥", "åŸºæœ¬", "å•ä¸€", "æŸ¥çœ‹", "è¯»å–"]
        
        complex_count = sum(1 for kw in complex_keywords if kw in task_lower)
        simple_count = sum(1 for kw in simple_keywords if kw in kw in task_lower)
        
        # åŸºäºé•¿åº¦å’Œå…³é”®è¯çš„ç®€å•åˆ¤æ–­
        if len(task_description.split()) > 30 or complex_count > 2:
            return "high"
        elif len(task_description.split()) > 15 or complex_count > 0:
            return "medium"
        else:
            return "low"
    
    def identify_input_requirements(self, task_description: str) -> List[str]:
        """è¯†åˆ«è¾“å…¥éœ€æ±‚"""
        requirements = []
        task_lower = task_description.lower()
        
        if "è·¯å¾„" in task_description or "path" in task_lower or "æ–‡ä»¶" in task_description:
            requirements.append("path")
        
        if "å†…å®¹" in task_description or "content" in task_lower or "æ–‡æœ¬" in task_description:
            requirements.append("content")
        
        if "æŸ¥è¯¢" in task_description or "query" in task_lower or "æœç´¢" in task_description:
            requirements.append("query")
        
        if "url" in task_lower or "é“¾æ¥" in task_description or "ç½‘å€" in task_description:
            requirements.append("url")
        
        if "å‘½ä»¤" in task_description or "command" in task_lower:
            requirements.append("command")
        
        if "æ ‡é¢˜" in task_description or "title" in task_lower:
            requirements.append("title")
        
        return requirements
    
    def identify_output_expectation(self, task_description: str) -> str:
        """è¯†åˆ«è¾“å‡ºæœŸæœ›"""
        task_lower = task_description.lower()
        
        if "æ–‡æ¡£" in task_description or "doc" in task_lower:
            return "document"
        
        if "æ–‡ä»¶" in task_description or "file" in task_lower:
            return "file"
        
        if "ç»“æœ" in task_description or "result" in task_lower or "æœç´¢" in task_description:
            return "search_results"
        
        if "å†…å®¹" in task_description or "content" in task_lower or "æ–‡æœ¬" in task_description:
            return "content"
        
        if "å‘½ä»¤" in task_description or "command" in task_lower or "æ‰§è¡Œ" in task_description:
            return "command_output"
        
        return "unknown"
    
    def extract_keywords(self, task_description: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPï¼‰
        words = re.findall(r'\b\w+\b', task_description.lower())
        
        # è¿‡æ»¤å¸¸è§åœç”¨è¯
        stop_words = {"çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸€ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™"}
        
        keywords = [word for word in words if word not in stop_words and len(word) > 1]
        
        return list(set(keywords))
    
    def recommend_tools(self, task_analysis: Dict, available_tools: List[str] = None, user_context: Dict = None) -> List[Dict]:
        """
        æ¨èå·¥å…·
        
        Args:
            task_analysis: ä»»åŠ¡åˆ†æç»“æœ
            available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡
            
        Returns:
            å·¥å…·æ¨èåˆ—è¡¨
        """
        if available_tools is None:
            available_tools = list(self.tools_db.keys())
        
        recommendations = []
        
        for tool_name in available_tools:
            if tool_name not in self.tools_db:
                continue
            
            tool_info = self.tools_db[tool_name]
            score = self.calculate_tool_score(tool_name, tool_info, task_analysis, user_context)
            
            if score > 0:
                recommendations.append({
                    "tool": tool_name,
                    "description": tool_info.get("description", ""),
                    "score": score,
                    "match_reasons": self.get_match_reasons(tool_name, tool_info, task_analysis),
                    "success_rate": tool_info.get("success_rate", 0.5),
                    "avg_response_time": tool_info.get("avg_response_time", 5.0),
                    "complexity": tool_info.get("complexity", "unknown"),
                    "permissions_required": tool_info.get("permissions_required", []),
                    "input_compatibility": self.check_input_compatibility(tool_info, task_analysis),
                    "output_compatibility": self.check_output_compatibility(tool_info, task_analysis)
                })
        
        # æŒ‰åˆ†æ•°æ’åº
        recommendations.sort(key=lambda x: x["score"], reverse=True)
        
        return recommendations
    
    def calculate_tool_score(self, tool_name: str, tool_info: Dict, task_analysis: Dict, user_context: Dict = None) -> float:
        """è®¡ç®—å·¥å…·åŒ¹é…åˆ†æ•°"""
        score = 0.0
        
        # 1. ä»»åŠ¡ç±»å‹åŒ¹é…ï¼ˆ40%ï¼‰
        task_types = task_analysis.get("task_types", [])
        tool_capabilities = tool_info.get("capabilities", [])
        
        for task_type in task_types:
            if task_type in self.task_patterns:
                if tool_name in self.task_patterns[task_type]["tools"]:
                    score += 4.0
        
        # 2. å…³é”®è¯åŒ¹é…ï¼ˆ20%ï¼‰
        keywords = task_analysis.get("keywords", [])
        tool_description = tool_info.get("description", "").lower()
        
        for keyword in keywords:
            if keyword in tool_description:
                score += 1.0
        
        # 3. è¾“å…¥è¾“å‡ºå…¼å®¹æ€§ï¼ˆ20%ï¼‰
        input_comp = self.check_input_compatibility(tool_info, task_analysis)
        output_comp = self.check_output_compatibility(tool_info, task_analysis)
        
        if input_comp["compatibility_score"] > 0.7:
            score += 1.0
        
        if output_comp["compatibility_score"] > 0.7:
            score += 1.0
        
        # 4. å†å²æˆåŠŸç‡ï¼ˆ10%ï¼‰
        success_rate = tool_info.get("success_rate", 0.5)
        score += success_rate
        
        # 5. å“åº”æ—¶é—´ï¼ˆ10%ï¼‰
        avg_time = tool_info.get("avg_response_time", 5.0)
        if avg_time < 2.0:
            score += 1.0
        elif avg_time < 5.0:
            score += 0.5
        
        # 6. ç”¨æˆ·åå¥½ï¼ˆå¦‚æœæœ‰ï¼‰
        if user_context and "preferred_tools" in user_context:
            if tool_name in user_context["preferred_tools"]:
                score += 2.0
        
        return score
    
    def get_match_reasons(self, tool_name: str, tool_info: Dict, task_analysis: Dict) -> List[str]:
        """è·å–åŒ¹é…åŸå› """
        reasons = []
        
        # ä»»åŠ¡ç±»å‹åŒ¹é…
        task_types = task_analysis.get("task_types", [])
        for task_type in task_types:
            if task_type in self.task_patterns:
                if tool_name in self.task_patterns[task_type]["tools"]:
                    reasons.append(f"åŒ¹é…ä»»åŠ¡ç±»å‹: {task_type}")
        
        # å…³é”®è¯åŒ¹é…
        keywords = task_analysis.get("keywords", [])
        tool_description = tool_info.get("description", "").lower()
        
        matched_keywords = []
        for keyword in keywords:
            if keyword in tool_description:
                matched_keywords.append(keyword)
        
        if matched_keywords:
            reasons.append(f"åŒ¹é…å…³é”®è¯: {', '.join(matched_keywords[:3])}")
        
        # å¤æ‚åº¦åŒ¹é…
        task_complexity = task_analysis.get("complexity", "low")
        tool_complexity = tool_info.get("complexity", "unknown")
        
        if task_complexity == tool_complexity:
            reasons.append(f"å¤æ‚åº¦åŒ¹é…: {task_complexity}")
        
        return reasons
    
    def check_input_compatibility(self, tool_info: Dict, task_analysis: Dict) -> Dict:
        """æ£€æŸ¥è¾“å…¥å…¼å®¹æ€§"""
        tool_inputs = tool_info.get("input_requirements", [])
        task_inputs = task_analysis.get("input_requirements", [])
        
        matched = []
        missing = []
        
        for tool_input in tool_inputs:
            if tool_input in task_inputs:
                matched.append(tool_input)
            else:
                missing.append(tool_input)
        
        compatibility_score = len(matched) / max(len(tool_inputs), 1)
        
        return {
            "tool_inputs": tool_inputs,
            "task_inputs": task_inputs,
            "matched_inputs": matched,
            "missing_inputs": missing,
            "compatibility_score": compatibility_score
        }
    
    def check_output_compatibility(self, tool_info: Dict, task_analysis: Dict) -> Dict:
        """æ£€æŸ¥è¾“å‡ºå…¼å®¹æ€§"""
        tool_output = tool_info.get("output_type", "unknown")
        task_output = task_analysis.get("output_expectation", "unknown")
        
        # ç®€å•çš„è¾“å‡ºç±»å‹åŒ¹é…
        output_mapping = {
            "document": ["document_url", "wiki_url"],
            "file": ["file_content", "file_status", "file_list"],
            "content": ["extracted_content", "file_content"],
            "search_results": ["search_results"],
            "command_output": ["command_output"]
        }
        
        compatibility_score = 0.0
        if task_output in output_mapping:
            if tool_output in output_mapping[task_output]:
                compatibility_score = 1.0
        elif task_output == "unknown" or tool_output == "unknown":
            compatibility_score = 0.5
        
        return {
            "tool_output": tool_output,
            "task_output": task_output,
            "compatibility_score": compatibility_score
        }
    
    def format_recommendation_report(self, task_analysis: Dict, recommendations: List[Dict], top_n: int = 3) -> str:
        """æ ¼å¼åŒ–æ¨èæŠ¥å‘Š"""
        report = []
        report.append("=" * 70)
        report.append("LLMç—›ç‚¹åˆ†æå™¨ - æ™ºèƒ½å·¥å…·æ¨èæŠ¥å‘Š")
        report.append("=" * 70)
        report.append(f"ä»»åŠ¡: {task_analysis.get('task_description', 'æœªçŸ¥ä»»åŠ¡')}")
        report.append(f"ä»»åŠ¡ç±»å‹: {', '.join(task_analysis.get('task_types', ['æœªçŸ¥']))}")
        report.append(f"å¤æ‚åº¦: {task_analysis.get('complexity', 'æœªçŸ¥')}")
        report.append(f"å…³é”®è¯: {', '.join(task_analysis.get('keywords', ['æ— ']))[:10]}")
        report.append("-" * 70)
        
        # æ˜¾ç¤ºå‰Nä¸ªæ¨è
        top_recommendations = recommendations[:top_n]
        
        if not top_recommendations:
            report.append("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å·¥å…·æ¨è")
            report.append("=" * 70)
            return "\n".join(report)
        
        report.append(f"æ¨èå·¥å…· (å‰{len(top_recommendations)}ä¸ª):")
        
        for i, rec in enumerate(top_recommendations, 1):
            report.append(f"\n{i}. {rec['tool']} (åˆ†æ•°: {rec['score']:.2f})")
            report.append(f"   æè¿°: {rec['description']}")
            report.append(f"   åŒ¹é…åŸå› : {', '.join(rec['match_reasons'][:2])}")
            report.append(f"   æˆåŠŸç‡: {rec['success_rate']*100:.1f}%")
            report.append(f"   å¹³å‡å“åº”æ—¶é—´: {rec['avg_response_time']:.1f}ç§’")
            report.append(f"   å¤æ‚åº¦: {rec['complexity']}")
            
            # è¾“å…¥å…¼å®¹æ€§
            input_comp = rec.get('input_compatibility', {})
            if input_comp.get('missing_inputs'):
                report.append(f"   âš ï¸ éœ€è¦é¢å¤–è¾“å…¥: {', '.join(input_comp['missing_inputs'])}")
        
        report.append("-" * 70)
        report.append("ä½¿ç”¨å»ºè®®:")
        
        if top_recommendations:
            best_tool = top_recommendations[0]
            report.append(f"1. é¦–é€‰: {best_tool['tool']} (åˆ†æ•°æœ€é«˜)")
            
            if len(top_recommendations) > 1:
                report.append(f"2. å¤‡é€‰: {top_recommendations[1]['tool']} (åˆ†æ•°: {top_recommendations[1]['score']:.2f})")
            
            # ç‰¹å®šå·¥å…·çš„å»ºè®®
            if best_tool['tool'] == 'feishu_doc':
                report.append("   ğŸ’¡ æ³¨æ„: feishu_doc.create(content='...') ä¼šå°†å†…å®¹å†™å…¥æ ‡é¢˜")
                report.append("       å»ºè®®ä½¿ç”¨ä¸¤æ­¥æ“ä½œ: 1) åˆ›å»ºæ ‡é¢˜ 2) update_blockæ·»åŠ å†…å®¹")
            
            if best_tool.get('permissions_required'):
                report.append(f"   ğŸ”‘ æ‰€éœ€æƒé™: {', '.join(best_tool['permissions_required'][:3])}")
        
        report.append("=" * 70)
        return "\n".join(report)


def main():
    """å‘½ä»¤è¡Œå…¥å£ç‚¹"""
    parser = argparse.ArgumentParser(description="LLMç—›ç‚¹åˆ†æå™¨ - å·¥å…·æ¨èæ¨¡å—")
    parser.add_argument("task", help="ä»»åŠ¡æè¿°")
    parser.add_argument("--config-dir", help="é…ç½®æ–‡ä»¶ç›®å½•")
    parser.add_argument("--top", type=int, default=3, help="æ˜¾ç¤ºå‰Nä¸ªæ¨è")
    parser.add_argument("--format", choices=["json", "text"], default="text", help="è¾“å‡ºæ ¼å¼")
    
    args = parser.parse_args()
    
    recommender = ToolRecommender(args.config_dir)
    
    # åˆ†æä»»åŠ¡
    task_analysis = recommender.analyze_task(args.task)
    
    # æ¨èå·¥å…·
    recommendations = recommender.recommend_tools(task_analysis)
    
    if args.format == "json":
        result = {
            "task_analysis": task_analysis,
            "recommendations": recommendations[:args.top]
        }
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print(recommender.format_recommendation_report(task_analysis, recommendations, args.top))


if __name__ == "__main__":
    main()